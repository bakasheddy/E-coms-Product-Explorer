# test

link to the scraped data is [here](https://drive.google.com/drive/folders/1F4YVmGjnaF63L6JrsYvwAXVaeHd7ej5L?usp=drive_link)

### module 1
- the data was loaded using pandas on google colab and local jupyter notebook and each feature was thoroughly examined for anomalys
- regular expression was utilzedd for the cleaning on features which had repeated patterns of untidiness
- features was converted to there appropriate data types
- duplicates and NAN values that could not be helped was dropped and a clean_data was downloaded


  ### Module 2
  - 
